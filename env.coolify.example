# =============================================================================
# SKYVERN COOLIFY MINIMAL CONFIGURATION
# =============================================================================
# This is a minimal configuration file for deploying Skyvern to Coolify.
# Copy this to .env and configure the required values below.

# =============================================================================
# REQUIRED: BASIC CONFIGURATION
# =============================================================================

# Environment
ENV=production

# Port (Coolify will handle the external mapping)
PORT=8000

# =============================================================================
# REQUIRED: DATABASE CONFIGURATION
# =============================================================================
# For Coolify, create a PostgreSQL service and link it to your Skyvern deployment
# The DATABASE_STRING format should be:
# postgresql+psycopg://USERNAME:PASSWORD@HOSTNAME:5432/DATABASE_NAME
#
# In Coolify, you can reference the PostgreSQL service hostname directly
# Example: postgresql+psycopg://skyvern:skyvern@postgres:5432/skyvern

DATABASE_STRING=postgresql+psycopg://skyvern:skyvern@postgres:5432/skyvern

# =============================================================================
# REQUIRED: LLM PROVIDER CONFIGURATION
# =============================================================================
# You MUST enable at least ONE LLM provider and set LLM_KEY
# Uncomment and configure ONE of the following:

# Option 1: OpenAI
# ENABLE_OPENAI=true
# OPENAI_API_KEY=sk-your-api-key-here
# LLM_KEY=OPENAI_GPT4O

# Option 2: Anthropic (Claude)
# ENABLE_ANTHROPIC=true
# ANTHROPIC_API_KEY=sk-ant-your-api-key-here
# LLM_KEY=ANTHROPIC_CLAUDE3.5_SONNET

# Option 3: Azure OpenAI
# ENABLE_AZURE=true
# AZURE_DEPLOYMENT=your-deployment-name
# AZURE_API_KEY=your-azure-api-key
# AZURE_API_BASE=https://your-resource.openai.azure.com/
# AZURE_API_VERSION=2024-08-01-preview
# LLM_KEY=AZURE_OPENAI

# Option 4: Gemini
# ENABLE_GEMINI=true
# GEMINI_API_KEY=your-gemini-api-key
# LLM_KEY=GEMINI

# =============================================================================
# REQUIRED: BROWSER CONFIGURATION
# =============================================================================
# Use headless browser for production/Coolify
BROWSER_TYPE=chromium-headless
BROWSER_ACTION_TIMEOUT_MS=5000
MAX_SCRAPING_RETRIES=3

# =============================================================================
# REQUIRED: STORAGE PATHS
# =============================================================================
# These paths are used for artifacts, videos, and logs
# In Coolify, you can mount persistent volumes to these paths
VIDEO_PATH=/data/videos
HAR_PATH=/data/har
LOG_PATH=/data/log
ARTIFACT_STORAGE_PATH=/data/artifacts

# =============================================================================
# OPTIONAL: AGENT CONFIGURATION
# =============================================================================
MAX_STEPS_PER_RUN=50
LOG_LEVEL=INFO
ANALYTICS_ID=anonymous
ENABLE_LOG_ARTIFACTS=false

# =============================================================================
# OPTIONAL: DATABASE MIGRATION
# =============================================================================
# Set this to skip migrations if you're rolling back to an older version
# Use at your own risk! Get the version from: SELECT * FROM alembic_version
# ALLOWED_SKIP_DB_MIGRATION_VERSION=abc123def456

# =============================================================================
# OPTIONAL: BITWARDEN/1PASSWORD INTEGRATION
# =============================================================================
# Uncomment if you want to integrate with Bitwarden for credential management
# SKYVERN_AUTH_BITWARDEN_ORGANIZATION_ID=your-org-id
# SKYVERN_AUTH_BITWARDEN_CLIENT_ID=user.your-client-id
# SKYVERN_AUTH_BITWARDEN_CLIENT_SECRET=your-client-secret
# SKYVERN_AUTH_BITWARDEN_MASTER_PASSWORD=your-master-password
# BITWARDEN_SERVER=http://bitwarden-cli
# BITWARDEN_SERVER_PORT=8087

# Uncomment if you want to integrate with 1Password
# OP_SERVICE_ACCOUNT_TOKEN=your-1password-token

# =============================================================================
# ADVANCED: ADDITIONAL LLM PROVIDERS
# =============================================================================
# For advanced users who want to use multiple LLM providers or specific models

# Secondary LLM for simpler tasks (optional, defaults to LLM_KEY if not set)
# SECONDARY_LLM_KEY=OPENAI_GPT4O_MINI

# Amazon Bedrock
# ENABLE_BEDROCK=true
# LLM_KEY=BEDROCK_ANTHROPIC_CLAUDE3.5_SONNET
# AWS_REGION=us-west-2
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key

# Ollama (for self-hosted LLMs)
# ENABLE_OLLAMA=true
# LLM_KEY=OLLAMA
# OLLAMA_MODEL=qwen2.5:7b-instruct
# OLLAMA_SERVER_URL=http://ollama:11434

# OpenRouter
# ENABLE_OPENROUTER=true
# LLM_KEY=OPENROUTER
# OPENROUTER_API_KEY=your-api-key
# OPENROUTER_MODEL=mistralai/mistral-small-3.1-24b-instruct

# Groq
# ENABLE_GROQ=true
# LLM_KEY=GROQ
# GROQ_API_KEY=your-groq-api-key
# GROQ_MODEL=llama-3.1-8b-instant

# Novita AI
# ENABLE_NOVITA=true
# NOVITA_API_KEY=your-novita-api-key

# Volcengine (ByteDance Doubao)
# ENABLE_VOLCENGINE=true
# VOLCENGINE_API_KEY=your-volcengine-api-key
# VOLCENGINE_API_BASE=https://ark.cn-beijing.volces.com/api/v3
